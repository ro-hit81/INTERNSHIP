{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ro-hit81/hello-world/blob/master/deep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po8SmZtiqsH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cJzJSSmqxNr",
        "colab_type": "code",
        "outputId": "c1a19298-1293-4292-c9a2-154e13b9c9c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below. \n",
            "Enter verification code: 4/vQERvBq-b7ZUxyVk_vFYv2bxGC5lwElfdEmN5VRd0lOoRm8j53Dlvx0\n",
            "\n",
            "Successfully saved authorization token.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlHlOq7brUjn",
        "colab_type": "code",
        "outputId": "8bfd26b0-657a-4ebe-e60d-b15855e8a3ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAs5NaFxrr1X",
        "colab_type": "code",
        "outputId": "0ee9957d-a153-40fb-da1d-dec8bc6db94b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        }
      },
      "source": [
        "import folium\n",
        "bands = ['B2', 'B3', 'B4', 'B8', 'B11', 'B12', 'QA60']\n",
        "bound = ee.FeatureCollection('users/rhtkhati/Ubon_Boundary')\n",
        "def maskS2clouds(image):\n",
        "    qa = image.select('QA60')\n",
        "    cloudBitMask = 1 << 10\n",
        "    cirrusBitMask = 1 << 11\n",
        "    mask = qa.bitwiseAnd(cloudBitMask).eq(0)\n",
        "    mask = mask.bitwiseAnd(cirrusBitMask).eq(0)\n",
        "\n",
        "    return image.updateMask(mask).divide(10000)\n",
        "collection = (ee.ImageCollection(\"COPERNICUS/S2\")\n",
        "              .select(bands)\n",
        "              .filter(ee.Filter.date('2019-01-01', '2019-03-31'))\n",
        "              .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 1))\n",
        "              .map(maskS2clouds)\n",
        "             )\n",
        "def add_ee_layer(self, eeImageObject, visParams, name):\n",
        "  mapID = ee.Image(eeImageObject).getMapId(visParams)\n",
        "  folium.TileLayer(\n",
        "    tiles = mapID['tile_fetcher'].url_format,\n",
        "    attr = \"Map Data Â© Google Earth Engine\",\n",
        "    name = name,\n",
        "    overlay = True,\n",
        "    control = True\n",
        "  ).add_to(self)\n",
        "folium.Map.add_ee_layer = add_ee_layer\n",
        "image = collection.sort('system:index', opt_ascending=False).mosaic()\n",
        "image = image.clip(bound)\n",
        "visParams = {'bands': [\"B4\",\"B3\",\"B2\"],\n",
        "            'max': 0.4,\n",
        "            'min': 0\n",
        "                }\n",
        "myMap = folium.Map(location = [15.2448, 104.8473])\n",
        "myMap.add_ee_layer(image, visParams, 'sen')\n",
        "myMap.add_child(folium.LayerControl())\n",
        "myMap"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,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\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ],
            "text/plain": [
              "<folium.folium.Map at 0x7fb24b258320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clBRwvnDA_dj",
        "colab_type": "code",
        "outputId": "16f6988b-1319-4101-ff0a-a9a911a2d65c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "labels = ee.FeatureCollection('users/rhtkhati/ubon_lulcpoint')\n",
        "label = 'lulcid'\n",
        "sample = image.sampleRegions(\n",
        "    collection = labels, properties = [label], scale = 10).randomColumn()\n",
        "training = sample.filter(ee.Filter.lt('random', 0.7))\n",
        "testing = sample.filter(ee.Filter.gte('random', 0.7))\n",
        "from pprint import pprint\n",
        "pprint({'training': training.first().getInfo()})\n",
        "pprint({'testing': testing.first().getInfo()})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'training': {'geometry': None,\n",
            "              'id': '00000000000000000000_0',\n",
            "              'properties': {'B11': 0.23409999907016754,\n",
            "                             'B12': 0.12110000103712082,\n",
            "                             'B2': 0.1136000007390976,\n",
            "                             'B3': 0.11020000278949738,\n",
            "                             'B4': 0.10480000078678131,\n",
            "                             'B8': 0.28439998626708984,\n",
            "                             'QA60': 0,\n",
            "                             'lulcid': 1,\n",
            "                             'random': 0.43497934351769174},\n",
            "              'type': 'Feature'}}\n",
            "{'testing': {'geometry': None,\n",
            "             'id': '00000000000000000006_0',\n",
            "             'properties': {'B11': 0.2069000005722046,\n",
            "                            'B12': 0.09600000083446503,\n",
            "                            'B2': 0.10159999877214432,\n",
            "                            'B3': 0.09560000151395798,\n",
            "                            'B4': 0.07999999821186066,\n",
            "                            'B8': 0.2703999876976013,\n",
            "                            'QA60': 0,\n",
            "                            'lulcid': 1,\n",
            "                            'random': 0.9814527905797661},\n",
            "             'type': 'Feature'}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W2G8ddQFvdB",
        "colab_type": "code",
        "outputId": "19c36526-b60a-4562-82cc-d01e1274188c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "outputBucket = 'gic-rohit12.appspot.com'\n",
        "print('Found Cloud Storage bucket.' if tf.gfile.Exists('gs://' + outputBucket) \n",
        "    else 'Output Cloud Storage bucket does not exist.')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found Cloud Storage bucket.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6Nb9J62Fwa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainFilePrefix = 'Training_demo'\n",
        "testFilePrefix = 'Testing_demo'\n",
        "featureNames = list(bands)\n",
        "featureNames.append(label)\n",
        "\n",
        "trainingTask = ee.batch.Export.table.toCloudStorage(\n",
        "  collection = training,\n",
        "  description ='Training Export',\n",
        "  fileNamePrefix = trainFilePrefix,\n",
        "  bucket = outputBucket,\n",
        "  fileFormat = 'TFRecord',\n",
        "  selectors = featureNames)\n",
        "\n",
        "testingTask = ee.batch.Export.table.toCloudStorage(\n",
        "  collection = testing,\n",
        "  description = 'Testing Export',\n",
        "  fileNamePrefix = testFilePrefix,\n",
        "  bucket = outputBucket,\n",
        "  fileFormat = 'TFRecord',\n",
        "  selectors = featureNames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odeaPPonTEoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainingTask.start()\n",
        "testingTask.start()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YACOd8xyVrlG",
        "colab_type": "code",
        "outputId": "7626bb5c-7092-4ca5-8d84-317a3e50d29c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print(ee.batch.Task.list())\n",
        "import time \n",
        "while trainingTask.active():\n",
        "  print('Polling for task (id: {}).'.format(trainingTask.id))\n",
        "  time.sleep(30)\n",
        "print('Done with training export.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<Task EXPORT_FEATURES: Testing Export (READY)>, <Task EXPORT_FEATURES: Training Export (READY)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (COMPLETED)>, <Task EXPORT_FEATURES: Training Export (COMPLETED)>, <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (COMPLETED)>, <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (CANCELLED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (COMPLETED)>, <Task EXPORT_FEATURES: Training Export (COMPLETED)>, <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (CANCELLED)>, <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (FAILED)>, <Task INGEST_IMAGE: Ingest image: \"projects/earthengine-legacy/assets/users/rhtkhati/Classified_pixel_demo\" (FAILED)>, <Task INGEST_IMAGE: Ingest image: \"projects/earthengine-legacy/assets/users/rhtkhati/Classified_pixel_demo\" (FAILED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (COMPLETED)>, <Task EXPORT_FEATURES: Training Export (COMPLETED)>, <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (FAILED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (COMPLETED)>, <Task EXPORT_FEATURES: Training Export (COMPLETED)>, <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (FAILED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (COMPLETED)>, <Task EXPORT_FEATURES: Training Export (COMPLETED)>, <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (FAILED)>, <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (COMPLETED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (COMPLETED)>, <Task EXPORT_FEATURES: Training Export (COMPLETED)>, <Task INGEST_TABLE: Ingest table: \"projects/earthengine-legacy/assets/users/rhtkhati/ubon_lulcpoint\" (COMPLETED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (COMPLETED)>, <Task EXPORT_FEATURES: Training Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (COMPLETED)>, <Task EXPORT_FEATURES: Training Export (COMPLETED)>, <Task INGEST_TABLE: Ingest table: \"projects/earthengine-legacy/assets/users/rhtkhati/feat_to_point\" (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (FAILED)>, <Task EXPORT_FEATURES: Training Export (FAILED)>, <Task INGEST_TABLE: Ingest table: \"projects/earthengine-legacy/assets/users/rhtkhati/lulc_mask_lulc\" (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (FAILED)>, <Task EXPORT_FEATURES: Training Export (FAILED)>, <Task EXPORT_FEATURES: Testing Export (FAILED)>, <Task EXPORT_FEATURES: Training Export (FAILED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (FAILED)>, <Task EXPORT_FEATURES: Training Export (FAILED)>, <Task EXPORT_FEATURES: Testing Export (FAILED)>, <Task EXPORT_FEATURES: Training Export (FAILED)>, <Task EXPORT_FEATURES: Testing Export (FAILED)>, <Task EXPORT_FEATURES: Training Export (FAILED)>, <Task EXPORT_FEATURES: Testing Export (FAILED)>, <Task EXPORT_FEATURES: Training Export (FAILED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (FAILED)>, <Task EXPORT_FEATURES: Training Export (FAILED)>, <Task EXPORT_FEATURES: Testing Export (FAILED)>, <Task EXPORT_FEATURES: Training Export (FAILED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (FAILED)>, <Task EXPORT_FEATURES: Training Export (FAILED)>, <Task EXPORT_FEATURES: Testing Export (FAILED)>, <Task EXPORT_FEATURES: Training Export (FAILED)>, <Task INGEST_TABLE: Ingest table: \"projects/earthengine-legacy/assets/users/rhtkhati/ubon_lulc_84\" (COMPLETED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (FAILED)>, <Task EXPORT_FEATURES: Training Export (FAILED)>, <Task INGEST_TABLE: Ingest table: \"projects/earthengine-legacy/assets/users/rhtkhati/lulc_ubon_data\" (COMPLETED)>]\n",
            "Polling for task (id: QTEVILXSUPYFGF4DMITSXZDT).\n",
            "Done with training export.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFAYfCL-V3MH",
        "colab_type": "code",
        "outputId": "3d46e5e9-1fb1-4f46-92fc-244fea04e062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "fileNameSuffix = '.tfrecord.gz'\n",
        "trainFilePath = 'gs://' + outputBucket + '/' + trainFilePrefix + fileNameSuffix\n",
        "testFilePath = 'gs://' + outputBucket + '/' + testFilePrefix + fileNameSuffix\n",
        "\n",
        "print('Found training file.' if tf.gfile.Exists(trainFilePath) \n",
        "    else 'No training file found.')\n",
        "print('Found testing file.' if tf.gfile.Exists(testFilePath) \n",
        "    else 'No testing file found.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found training file.\n",
            "Found testing file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1pdDmJ5XN2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imageFilePrefix = 'Image_pixel_demo_'\n",
        "\n",
        "# Specify patch and file dimensions.\n",
        "imageExportFormatOptions = {\n",
        "  'patchDimensions': [256, 256],\n",
        "  'maxFileSize': 104857600,\n",
        "  'compressed': True\n",
        "}\n",
        "\n",
        "# Export imagery in this region.\n",
        "exportRegion = ee.Geometry.Rectangle([104.8473, 15.24, 104.6, 15.00])\n",
        "\n",
        "# Setup the task.\n",
        "imageTask = ee.batch.Export.image.toCloudStorage(\n",
        "  image=image,\n",
        "  description='Image Export',\n",
        "  fileNamePrefix=imageFilePrefix,\n",
        "  bucket=outputBucket,\n",
        "  scale=10,\n",
        "  fileFormat='TFRecord',\n",
        "  region=exportRegion.toGeoJSON()['coordinates'],\n",
        "  formatOptions=imageExportFormatOptions,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stjazI4NaXon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imageTask.start()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TJX7zJUabFD",
        "colab_type": "code",
        "outputId": "d3fc5054-2608-4182-df29-f0ff9e863d7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "while imageTask.active():\n",
        "  print('Polling for task (id: {}).'.format(imageTask.id))\n",
        "  time.sleep(30)\n",
        "print('Done with image export.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Polling for task (id: O6TRWJSNNYL4ZPRPVM5UYGCP).\n",
            "Polling for task (id: O6TRWJSNNYL4ZPRPVM5UYGCP).\n",
            "Polling for task (id: O6TRWJSNNYL4ZPRPVM5UYGCP).\n",
            "Polling for task (id: O6TRWJSNNYL4ZPRPVM5UYGCP).\n",
            "Polling for task (id: O6TRWJSNNYL4ZPRPVM5UYGCP).\n",
            "Polling for task (id: O6TRWJSNNYL4ZPRPVM5UYGCP).\n",
            "Polling for task (id: O6TRWJSNNYL4ZPRPVM5UYGCP).\n",
            "Done with image export.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJB3v3mfafQb",
        "colab_type": "code",
        "outputId": "299a6d7a-ad40-4194-dfc5-964ba0cdf18a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "trainDataset = tf.data.TFRecordDataset(trainFilePath, compression_type='GZIP')\n",
        "print(iter(trainDataset).next())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'\\n\\x88\\x01\\n\\x0e\\n\\x02B2\\x12\\x08\\x12\\x06\\n\\x04\\x1e\\xa7\\xe8=\\n\\x0e\\n\\x02B3\\x12\\x08\\x12\\x06\\n\\x04\\x8a\\xb0\\xe1=\\n\\x0e\\n\\x02B4\\x12\\x08\\x12\\x06\\n\\x04b\\xa1\\xd6=\\n\\x0e\\n\\x02B8\\x12\\x08\\x12\\x06\\n\\x04\\xe0\\x9c\\x91>\\n\\x0f\\n\\x03B11\\x12\\x08\\x12\\x06\\n\\x04\\xe9\\xb7o>\\n\\x0f\\n\\x03B12\\x12\\x08\\x12\\x06\\n\\x04G\\x03\\xf8=\\n\\x10\\n\\x04QA60\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n\\x12\\n\\x06lulcid\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x80?', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3I0ps75gRNM",
        "colab_type": "code",
        "outputId": "560ca34e-5050-43ae-99d6-880e41c24071",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "columns = [\n",
        "  tf.io.FixedLenFeature(shape=[1], dtype=tf.float32) for k in featureNames\n",
        "]\n",
        "\n",
        "# Dictionary with names as keys, features as values.\n",
        "featuresDict = dict(zip(featureNames, columns))\n",
        "\n",
        "pprint(featuresDict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'B11': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " 'B12': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " 'B2': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " 'B3': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " 'B4': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " 'B8': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " 'QA60': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " 'lulcid': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqN5hdHCv5KL",
        "colab_type": "code",
        "outputId": "93adb49d-1334-451a-8177-3cff13526980",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "def parse_tfrecord(example_proto):\n",
        "  \"\"\"The parsing function.\n",
        "\n",
        "  Read a serialized example into the structure defined by featuresDict.\n",
        "\n",
        "  Args:\n",
        "    example_proto: a serialized Example.\n",
        "  \n",
        "  Returns: \n",
        "    A tuple of the predictors dictionary and the label, cast to an `int32`.\n",
        "  \"\"\"\n",
        "  parsed_features = tf.io.parse_single_example(example_proto, featuresDict)\n",
        "  labels = parsed_features.pop(label)\n",
        "  return parsed_features, tf.cast(labels, tf.int32)\n",
        "\n",
        "# Map the function over the dataset.\n",
        "parsedDataset = trainDataset.map(parse_tfrecord, num_parallel_calls=5)\n",
        "\n",
        "# Print the first parsed record to check.\n",
        "pprint(iter(parsedDataset).next())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "({'B11': <tf.Tensor: id=54, shape=(1,), dtype=float32, numpy=array([0.2341], dtype=float32)>,\n",
            "  'B12': <tf.Tensor: id=55, shape=(1,), dtype=float32, numpy=array([0.1211], dtype=float32)>,\n",
            "  'B2': <tf.Tensor: id=56, shape=(1,), dtype=float32, numpy=array([0.1136], dtype=float32)>,\n",
            "  'B3': <tf.Tensor: id=57, shape=(1,), dtype=float32, numpy=array([0.1102], dtype=float32)>,\n",
            "  'B4': <tf.Tensor: id=58, shape=(1,), dtype=float32, numpy=array([0.1048], dtype=float32)>,\n",
            "  'B8': <tf.Tensor: id=59, shape=(1,), dtype=float32, numpy=array([0.2844], dtype=float32)>,\n",
            "  'QA60': <tf.Tensor: id=60, shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>},\n",
            " <tf.Tensor: id=61, shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNimLVa06mqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalizedDifference(a, b):\n",
        "  \"\"\"Compute normalized difference of two inputs.\n",
        "\n",
        "  Compute (a - b) / (a + b).  If the denomenator is zero, add a small delta.  \n",
        "\n",
        "  Args:\n",
        "    a: an input tensor with shape=[1]\n",
        "    b: an input tensor with shape=[1]\n",
        "\n",
        "  Returns:\n",
        "    The normalized difference as a tensor.\n",
        "  \"\"\"\n",
        "  nd = (a - b) / (a + b)\n",
        "  nd_inf = (a - b) / (a + b + 0.000001)\n",
        "  return tf.where(tf.math.is_finite(nd), nd, nd_inf)\n",
        "\n",
        "def addNDVI(features, label):\n",
        "  \"\"\"Add NDVI to the dataset.\n",
        "  Args: \n",
        "    features: a dictionary of input tensors keyed by feature name.\n",
        "    label: the target label\n",
        "  \n",
        "  Returns:\n",
        "    A tuple of the input dictionary with an NDVI tensor added and the label.\n",
        "  \"\"\"\n",
        "  features['NDVI'] = normalizedDifference(features['B8'], features['B4'])\n",
        "  return features, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q73ZLNM6yhn",
        "colab_type": "code",
        "outputId": "ccc834a2-066f-4568-838e-055000c4fdb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        }
      },
      "source": [
        "from tensorflow import keras\n",
        "nClasses = 5\n",
        "inputDataset = parsedDataset.map(addNDVI)\n",
        "def toTuple(dict, label):\n",
        "  return tf.transpose(list(dict.values())), tf.one_hot(indices=label, depth=nClasses)\n",
        "inputDataset = inputDataset.map(toTuple).repeat().batch(10)\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(nClasses, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x=inputDataset, epochs=10, steps_per_epoch=100)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-21-577210d1a9a8>:15: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.9464 - acc: 0.7063\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4824 - acc: 0.8074\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.4440 - acc: 0.7998\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4285 - acc: 0.7915\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4208 - acc: 0.7824\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4271 - acc: 0.7720\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4118 - acc: 0.7597\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4235 - acc: 0.7432\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4320 - acc: 0.7382\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.4027 - acc: 0.7743\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb235960b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJpx2DLS7oAG",
        "colab_type": "code",
        "outputId": "bc8a7ecf-9720-47fa-a120-519ff0046164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "testDataset = (\n",
        "  tf.data.TFRecordDataset(testFilePath, compression_type='GZIP')\n",
        "    .map(parse_tfrecord, num_parallel_calls=5)\n",
        "    .map(addNDVI)\n",
        "    .map(toTuple)\n",
        "    .batch(1)\n",
        ")\n",
        "\n",
        "model.evaluate(testDataset, steps=45)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 1s 19ms/step - loss: 0.6557 - acc: 0.6889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6556985729270511, 0.6888889]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhibYc4a8Yth",
        "colab_type": "code",
        "outputId": "33334481-6e5a-47f6-d983-6828311dec82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "filesList = !gsutil ls 'gs://'{outputBucket}\n",
        "# Get only the files generated by the image export.\n",
        "exportFilesList = [s for s in filesList if imageFilePrefix in s]\n",
        "\n",
        "# Get the list of image files and the JSON mixer file.\n",
        "imageFilesList = []\n",
        "jsonFile = None\n",
        "for f in exportFilesList:\n",
        "  if f.endswith('.tfrecord.gz'):\n",
        "    imageFilesList.append(f)\n",
        "  elif f.endswith('.json'):\n",
        "    jsonFile = f\n",
        "\n",
        "# Make sure the files are in the right order.\n",
        "imageFilesList.sort()\n",
        "\n",
        "pprint(imageFilesList)\n",
        "print(jsonFile)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['gs://gic-rohit12.appspot.com/Image_pixel_demo_00000.tfrecord.gz',\n",
            " 'gs://gic-rohit12.appspot.com/Image_pixel_demo_00001.tfrecord.gz']\n",
            "gs://gic-rohit12.appspot.com/Image_pixel_demo_mixer.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRK7EH8i8iMK",
        "colab_type": "code",
        "outputId": "16d61c9a-d195-48b4-ef9b-94cdc60eed5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "import json\n",
        "\n",
        "# Load the contents of the mixer file to a JSON object.\n",
        "jsonText = !gsutil cat {jsonFile}\n",
        "# Get a single string w/ newlines from the IPython.utils.text.SList\n",
        "mixer = json.loads(jsonText.nlstr)\n",
        "pprint(mixer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'patchDimensions': [256, 256],\n",
            " 'patchesPerRow': 10,\n",
            " 'projection': {'affine': {'doubleMatrix': [8.983152841195215e-05,\n",
            "                                            0.0,\n",
            "                                            104.5999215144055,\n",
            "                                            0.0,\n",
            "                                            -8.983152841195215e-05,\n",
            "                                            15.240008626616094]},\n",
            "                'crs': 'EPSG:4326'},\n",
            " 'totalPatches': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1rx4KDU8j0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATCH_WIDTH = mixer['patchDimensions'][0]\n",
        "PATCH_HEIGHT = mixer['patchDimensions'][1]\n",
        "PATCHES = mixer['totalPatches']\n",
        "PATCH_DIMENSIONS_FLAT = [PATCH_WIDTH * PATCH_HEIGHT, 1]\n",
        "\n",
        "# Note that the tensors are in the shape of a patch, one patch for each band.\n",
        "imageColumns = [\n",
        "  tf.FixedLenFeature(shape=PATCH_DIMENSIONS_FLAT, dtype=tf.float32) \n",
        "    for k in bands\n",
        "]\n",
        "\n",
        "# Parsing dictionary.\n",
        "imageFeaturesDict = dict(zip(bands, imageColumns))\n",
        "\n",
        "# Note that you can make one dataset from many files by specifying a list.\n",
        "imageDataset = tf.data.TFRecordDataset(imageFilesList, compression_type='GZIP')\n",
        "\n",
        "# Parsing function.\n",
        "def parse_image(example_proto):\n",
        "  return tf.io.parse_single_example(example_proto, imageFeaturesDict)\n",
        "\n",
        "# Parse the data into tensors, one long tensor per patch.\n",
        "imageDataset = imageDataset.map(parse_image, num_parallel_calls=5)\n",
        "\n",
        "# Break our long tensors into many little ones.\n",
        "imageDataset = imageDataset.flat_map(\n",
        "  lambda features: tf.data.Dataset.from_tensor_slices(features)\n",
        ")\n",
        "\n",
        "# Add additional features (NDVI).\n",
        "imageDataset = imageDataset.map(\n",
        "  # Add NDVI to a feature that doesn't have a label.\n",
        "  lambda features: addNDVI(features, None)[0]\n",
        ")\n",
        "\n",
        "# Turn the dictionary in each record into a tuple with a dummy label.\n",
        "imageDataset = imageDataset.map(\n",
        "  # Add a dummy target (-1), with a value that is obviously ridiculous.\n",
        "  # This is because the model expects a tuple of (inputs, label).\n",
        "  lambda dataDict: (tf.transpose(list(dataDict.values())), tf.constant(-1))\n",
        ")\n",
        "\n",
        "# Turn each patch into a batch.\n",
        "imageDataset = imageDataset.batch(PATCH_WIDTH * PATCH_HEIGHT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNduj14M8tl5",
        "colab_type": "code",
        "outputId": "6dcbe749-948e-4fd8-cd41-b8a30de48dc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "predictions = model.predict(imageDataset, steps=PATCHES, verbose=1)\n",
        "\n",
        "# Note that the predictions come as a numpy array.  Check the first one.\n",
        "print(predictions[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 691s 7s/step\n",
            "[[0.03816325 0.55483025 0.13747299 0.14411013 0.12542345]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py5ke9PE83T-",
        "colab_type": "code",
        "outputId": "2b35daeb-28f1-465e-85e1-689d0d18b629",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "outputImageFile = 'gs://' + outputBucket + '/Classified_pixel_demo.TFRecord'\n",
        "print('Writing to file ' + outputImageFile)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing to file gs://gic-rohit12.appspot.com/Classified_pixel_demo.TFRecord\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tnh_JP5F9Wl8",
        "colab_type": "code",
        "outputId": "7e22af7d-3878-47be-b66a-1c9d319056e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "writer = tf.python_io.TFRecordWriter(outputImageFile)\n",
        "\n",
        "# Every patch-worth of predictions we'll dump an example into the output\n",
        "# file with a single feature that holds our predictions. Since our predictions\n",
        "# are already in the order of the exported data, the patches we create here\n",
        "# will also be in the right order.\n",
        "patch = [[], [], [], [], [], []]\n",
        "curPatch = 1\n",
        "for prediction in predictions:\n",
        "  patch[0].append(tf.argmax(prediction, 1))\n",
        "  patch[1].append(prediction[0][0])\n",
        "  patch[2].append(prediction[0][1])\n",
        "  patch[3].append(prediction[0][2])\n",
        "  patch[4].append(prediction[0][3])\n",
        "  patch[5].append(prediction[0][4])\n",
        "  # Once we've seen a patches-worth of class_ids...\n",
        "  if (len(patch[0]) == PATCH_WIDTH * PATCH_HEIGHT):\n",
        "    print('Done with patch ' + str(curPatch) + ' of ' + str(PATCHES) + '...')\n",
        "    # Create an example\n",
        "    example = tf.train.Example(\n",
        "      features=tf.train.Features(\n",
        "        feature={\n",
        "          'prediction': tf.train.Feature(\n",
        "              int64_list=tf.train.Int64List(\n",
        "                  value=patch[0])),\n",
        "          'bareProb': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[1])),\n",
        "          'vegProb': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[2])),\n",
        "          'waterProb': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[3])),\n",
        "          'new1Prob': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[4])),\n",
        "          'new2Prob': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[5]))\n",
        "        }\n",
        "      )\n",
        "    )\n",
        "    # Write the example to the file and clear our patch array so it's ready for\n",
        "    # another batch of class ids\n",
        "    writer.write(example.SerializeToString())\n",
        "    patch = [[], [], [], [], [], []]\n",
        "    curPatch += 1\n",
        "\n",
        "writer.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done with patch 1 of 100...\n",
            "Done with patch 2 of 100...\n",
            "Done with patch 3 of 100...\n",
            "Done with patch 4 of 100...\n",
            "Done with patch 5 of 100...\n",
            "Done with patch 6 of 100...\n",
            "Done with patch 7 of 100...\n",
            "Done with patch 8 of 100...\n",
            "Done with patch 9 of 100...\n",
            "Done with patch 10 of 100...\n",
            "Done with patch 11 of 100...\n",
            "Done with patch 12 of 100...\n",
            "Done with patch 13 of 100...\n",
            "Done with patch 14 of 100...\n",
            "Done with patch 15 of 100...\n",
            "Done with patch 16 of 100...\n",
            "Done with patch 17 of 100...\n",
            "Done with patch 18 of 100...\n",
            "Done with patch 19 of 100...\n",
            "Done with patch 20 of 100...\n",
            "Done with patch 21 of 100...\n",
            "Done with patch 22 of 100...\n",
            "Done with patch 23 of 100...\n",
            "Done with patch 24 of 100...\n",
            "Done with patch 25 of 100...\n",
            "Done with patch 26 of 100...\n",
            "Done with patch 27 of 100...\n",
            "Done with patch 28 of 100...\n",
            "Done with patch 29 of 100...\n",
            "Done with patch 30 of 100...\n",
            "Done with patch 31 of 100...\n",
            "Done with patch 32 of 100...\n",
            "Done with patch 33 of 100...\n",
            "Done with patch 34 of 100...\n",
            "Done with patch 35 of 100...\n",
            "Done with patch 36 of 100...\n",
            "Done with patch 37 of 100...\n",
            "Done with patch 38 of 100...\n",
            "Done with patch 39 of 100...\n",
            "Done with patch 40 of 100...\n",
            "Done with patch 41 of 100...\n",
            "Done with patch 42 of 100...\n",
            "Done with patch 43 of 100...\n",
            "Done with patch 44 of 100...\n",
            "Done with patch 45 of 100...\n",
            "Done with patch 46 of 100...\n",
            "Done with patch 47 of 100...\n",
            "Done with patch 48 of 100...\n",
            "Done with patch 49 of 100...\n",
            "Done with patch 50 of 100...\n",
            "Done with patch 51 of 100...\n",
            "Done with patch 52 of 100...\n",
            "Done with patch 53 of 100...\n",
            "Done with patch 54 of 100...\n",
            "Done with patch 55 of 100...\n",
            "Done with patch 56 of 100...\n",
            "Done with patch 57 of 100...\n",
            "Done with patch 58 of 100...\n",
            "Done with patch 59 of 100...\n",
            "Done with patch 60 of 100...\n",
            "Done with patch 61 of 100...\n",
            "Done with patch 62 of 100...\n",
            "Done with patch 63 of 100...\n",
            "Done with patch 64 of 100...\n",
            "Done with patch 65 of 100...\n",
            "Done with patch 66 of 100...\n",
            "Done with patch 67 of 100...\n",
            "Done with patch 68 of 100...\n",
            "Done with patch 69 of 100...\n",
            "Done with patch 70 of 100...\n",
            "Done with patch 71 of 100...\n",
            "Done with patch 72 of 100...\n",
            "Done with patch 73 of 100...\n",
            "Done with patch 74 of 100...\n",
            "Done with patch 75 of 100...\n",
            "Done with patch 76 of 100...\n",
            "Done with patch 77 of 100...\n",
            "Done with patch 78 of 100...\n",
            "Done with patch 79 of 100...\n",
            "Done with patch 80 of 100...\n",
            "Done with patch 81 of 100...\n",
            "Done with patch 82 of 100...\n",
            "Done with patch 83 of 100...\n",
            "Done with patch 84 of 100...\n",
            "Done with patch 85 of 100...\n",
            "Done with patch 86 of 100...\n",
            "Done with patch 87 of 100...\n",
            "Done with patch 88 of 100...\n",
            "Done with patch 89 of 100...\n",
            "Done with patch 90 of 100...\n",
            "Done with patch 91 of 100...\n",
            "Done with patch 92 of 100...\n",
            "Done with patch 93 of 100...\n",
            "Done with patch 94 of 100...\n",
            "Done with patch 95 of 100...\n",
            "Done with patch 96 of 100...\n",
            "Done with patch 97 of 100...\n",
            "Done with patch 98 of 100...\n",
            "Done with patch 99 of 100...\n",
            "Done with patch 100 of 100...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPgMJPxM9XUg",
        "colab_type": "code",
        "outputId": "0deba1d2-de5a-4e4e-9040-cde4b4f808ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!gsutil ls -l {outputImageFile}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 137643400  2020-01-12T08:44:18Z  gs://gic-rohit12.appspot.com/Classified_pixel_demo.TFRecord\n",
            "TOTAL: 1 objects, 137643400 bytes (131.27 MiB)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSlUgpY79aK1",
        "colab_type": "code",
        "outputId": "8c3b1d41-5c04-41cd-ff2b-a406dc19ef70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "USER_NAME = 'rhtkhati'\n",
        "outputAssetID = 'users/' + USER_NAME + '/Classified_pixel_demo'\n",
        "print('Writing to ' + outputAssetID)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing to users/rhtkhati/Classified_pixel_demo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRycbtRD9rHN",
        "colab_type": "code",
        "outputId": "32e76b67-b075-4aaf-903b-49c639ae9b3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!earthengine --no-use_cloud_api upload image --asset_id={outputAssetID} {outputImageFile} {jsonFile}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Started upload task with ID: CLL5OHLQVLFIR5ZYROX5WYSN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRgzcVK19rrP",
        "colab_type": "code",
        "outputId": "a87d7334-6173-41d3-ed8a-a1d9f68a5f5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "ee.batch.Task.list()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (READY)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (COMPLETED)>,\n",
              " <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (CANCELLED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (CANCELLED)>,\n",
              " <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (FAILED)>,\n",
              " <Task INGEST_IMAGE: Ingest image: \"projects/earthengine-legacy/assets/users/rhtkhati/Classified_pixel_demo\" (FAILED)>,\n",
              " <Task INGEST_IMAGE: Ingest image: \"projects/earthengine-legacy/assets/users/rhtkhati/Classified_pixel_demo\" (FAILED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (FAILED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (FAILED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (FAILED)>,\n",
              " <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (COMPLETED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task INGEST_TABLE: Ingest table: \"projects/earthengine-legacy/assets/users/rhtkhati/ubon_lulcpoint\" (COMPLETED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task INGEST_TABLE: Ingest table: \"projects/earthengine-legacy/assets/users/rhtkhati/feat_to_point\" (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (FAILED)>,\n",
              " <Task INGEST_TABLE: Ingest table: \"projects/earthengine-legacy/assets/users/rhtkhati/lulc_mask_lulc\" (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (FAILED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (FAILED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (FAILED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (FAILED)>,\n",
              " <Task INGEST_TABLE: Ingest table: \"projects/earthengine-legacy/assets/users/rhtkhati/ubon_lulc_84\" (COMPLETED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (FAILED)>,\n",
              " <Task INGEST_TABLE: Ingest table: \"projects/earthengine-legacy/assets/users/rhtkhati/lulc_ubon_data\" (COMPLETED)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb3Hpd7M9t3G",
        "colab_type": "code",
        "outputId": "b57be6a8-40a3-4fb6-96b4-012514b1d9a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        }
      },
      "source": [
        "predictionsImage = ee.Image(outputAssetID)\n",
        "\n",
        "predictionVis = {\n",
        "  'bands': 'prediction',\n",
        "  'min': 0,\n",
        "  'max': 4,\n",
        "  'palette': ['red', 'yellow', 'blue']\n",
        "}\n",
        "probabilityVis = {'bands': ['bareProb', 'vegProb', 'waterProb']}\n",
        "\n",
        "predictionMapid = predictionsImage.getMapId(predictionVis)\n",
        "probabilityMapid = predictionsImage.getMapId(probabilityVis)\n",
        "\n",
        "map = folium.Map(location=[15.2448, 104.8473])\n",
        "folium.TileLayer(\n",
        "  tiles=predictionMapid['tile_fetcher'].url_format,\n",
        "  attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "  overlay=True,\n",
        "  name='prediction',\n",
        ").add_to(map)\n",
        "folium.TileLayer(\n",
        "  tiles=probabilityMapid['tile_fetcher'].url_format,\n",
        "  attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "  overlay=True,\n",
        "  name='probability',\n",
        ").add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,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\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ],
            "text/plain": [
              "<folium.folium.Map at 0x7fb2875c7f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Islnb5lz9xM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}