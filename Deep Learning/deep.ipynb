{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ro-hit81/INTERNSHIP/blob/master/Deep%20Learning/deep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po8SmZtiqsH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cJzJSSmqxNr",
        "colab_type": "code",
        "outputId": "c40eef42-18b7-4161-a6ca-80501bbace5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below. \n",
            "Enter verification code: 4/vQEW95v3vb4KnMKT3yKKUSYL9WjQD0bNg83FMB4dXYhWwhjOM_oSs_0\n",
            "\n",
            "Successfully saved authorization token.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlHlOq7brUjn",
        "colab_type": "code",
        "outputId": "2a0ca091-9d40-4adf-8fab-ae9b90e896a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAs5NaFxrr1X",
        "colab_type": "code",
        "outputId": "e6ed9f65-9554-4e29-d3ad-70729c66420d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import folium\n",
        "bands = ['B2', 'B3', 'B4', 'B8', 'B11', 'B12', 'QA60']\n",
        "bound = ee.FeatureCollection('users/rhtkhati/Ubon_Boundary')\n",
        "def maskS2clouds(image):\n",
        "    qa = image.select('QA60')\n",
        "    cloudBitMask = 1 << 10\n",
        "    cirrusBitMask = 1 << 11\n",
        "    mask = qa.bitwiseAnd(cloudBitMask).eq(0)\n",
        "    mask = mask.bitwiseAnd(cirrusBitMask).eq(0)\n",
        "\n",
        "    return image.updateMask(mask).divide(10000)\n",
        "collection = (ee.ImageCollection(\"COPERNICUS/S2\")\n",
        "              .select(bands)\n",
        "              .filter(ee.Filter.date('2019-01-01', '2019-03-31'))\n",
        "              .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 1))\n",
        "              .map(maskS2clouds)\n",
        "             )\n",
        "def add_ee_layer(self, eeImageObject, visParams, name):\n",
        "  mapID = ee.Image(eeImageObject).getMapId(visParams)\n",
        "  folium.TileLayer(\n",
        "    tiles = mapID['tile_fetcher'].url_format,\n",
        "    attr = \"Map Data Â© Google Earth Engine\",\n",
        "    name = name,\n",
        "    overlay = True,\n",
        "    control = True\n",
        "  ).add_to(self)\n",
        "folium.Map.add_ee_layer = add_ee_layer\n",
        "image = collection.sort('system:index', opt_ascending=False).mosaic()\n",
        "image = image.clip(bound)\n",
        "visParams = {'bands': [\"B4\",\"B3\",\"B2\"],\n",
        "            'max': 0.4,\n",
        "            'min': 0\n",
        "                }\n",
        "myMap = folium.Map(location = [15.2448, 104.8473])\n",
        "myMap.add_ee_layer(image, visParams, 'sen')\n",
        "myMap.add_child(folium.LayerControl())\n",
        "myMap"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,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\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ],
            "text/plain": [
              "<folium.folium.Map at 0x7f1c1d657470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clBRwvnDA_dj",
        "colab_type": "code",
        "outputId": "bed0b440-103b-4342-db38-838e57cd96e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "labels = ee.FeatureCollection('users/rhtkhati/ubon_lulcpoint')\n",
        "label = 'lulcid'\n",
        "sample = image.sampleRegions(\n",
        "    collection = labels, properties = [label], scale = 10).randomColumn()\n",
        "training = sample.filter(ee.Filter.lt('random', 0.7))\n",
        "testing = sample.filter(ee.Filter.gte('random', 0.7))\n",
        "from pprint import pprint\n",
        "pprint({'training': training.first().getInfo()})\n",
        "pprint({'testing': testing.first().getInfo()})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'training': {'geometry': None,\n",
            "              'id': '00000000000000000002_0',\n",
            "              'properties': {'B11': 0.37869998812675476,\n",
            "                             'B12': 0.2125999927520752,\n",
            "                             'B2': 0.12389999628067017,\n",
            "                             'B3': 0.1185000017285347,\n",
            "                             'B4': 0.1379999965429306,\n",
            "                             'B8': 0.24619999527931213,\n",
            "                             'QA60': 0,\n",
            "                             'lulcid': 1,\n",
            "                             'random': 0.5797738830534658},\n",
            "              'type': 'Feature'}}\n",
            "{'testing': {'geometry': None,\n",
            "             'id': '00000000000000000000_0',\n",
            "             'properties': {'B11': 0.23409999907016754,\n",
            "                            'B12': 0.12110000103712082,\n",
            "                            'B2': 0.1136000007390976,\n",
            "                            'B3': 0.11020000278949738,\n",
            "                            'B4': 0.10480000078678131,\n",
            "                            'B8': 0.28439998626708984,\n",
            "                            'QA60': 0,\n",
            "                            'lulcid': 1,\n",
            "                            'random': 0.9489041903608365},\n",
            "             'type': 'Feature'}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W2G8ddQFvdB",
        "colab_type": "code",
        "outputId": "9f0f8e10-b46c-49dc-800c-369e6d8631e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "outputBucket = 'gic-rohit12.appspot.com'\n",
        "print('Found Cloud Storage bucket.' if tf.gfile.Exists('gs://' + outputBucket) \n",
        "    else 'Output Cloud Storage bucket does not exist.')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found Cloud Storage bucket.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6Nb9J62Fwa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainFilePrefix = 'Training_demo'\n",
        "testFilePrefix = 'Testing_demo'\n",
        "featureNames = list(bands)\n",
        "featureNames.append(label)\n",
        "\n",
        "trainingTask = ee.batch.Export.table.toCloudStorage(\n",
        "  collection = training,\n",
        "  description ='Training Export',\n",
        "  fileNamePrefix = trainFilePrefix,\n",
        "  bucket = outputBucket,\n",
        "  fileFormat = 'TFRecord',\n",
        "  selectors = featureNames)\n",
        "\n",
        "testingTask = ee.batch.Export.table.toCloudStorage(\n",
        "  collection = testing,\n",
        "  description = 'Testing Export',\n",
        "  fileNamePrefix = testFilePrefix,\n",
        "  bucket = outputBucket,\n",
        "  fileFormat = 'TFRecord',\n",
        "  selectors = featureNames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odeaPPonTEoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainingTask.start()\n",
        "testingTask.start()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YACOd8xyVrlG",
        "colab_type": "code",
        "outputId": "20e6b197-c014-46ae-892d-bbc85d602cee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print(ee.batch.Task.list())\n",
        "import time \n",
        "while trainingTask.active():\n",
        "  print('Polling for task (id: {}).'.format(trainingTask.id))\n",
        "  time.sleep(30)\n",
        "print('Done with training export.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<Task EXPORT_FEATURES: Testing Export (READY)>, <Task EXPORT_FEATURES: Training Export (READY)>, <Task EXPORT_IMAGE: Deep_IMAGE (COMPLETED)>, <Task EXPORT_IMAGE: Deep_IMAGE (FAILED)>, <Task EXPORT_IMAGE: Deep_IMAGE (FAILED)>, <Task EXPORT_IMAGE: Deep_IMAGE (FAILED)>, <Task EXPORT_FEATURES: Testing Export (COMPLETED)>, <Task EXPORT_FEATURES: Training Export (COMPLETED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (COMPLETED)>, <Task EXPORT_FEATURES: Training Export (COMPLETED)>, <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (COMPLETED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (COMPLETED)>, <Task EXPORT_FEATURES: Training Export (COMPLETED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (COMPLETED)>, <Task EXPORT_FEATURES: Training Export (COMPLETED)>, <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (CANCELLED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (COMPLETED)>, <Task EXPORT_FEATURES: Training Export (COMPLETED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (COMPLETED)>, <Task EXPORT_FEATURES: Training Export (COMPLETED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (COMPLETED)>, <Task EXPORT_FEATURES: Training Export (COMPLETED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (COMPLETED)>, <Task EXPORT_FEATURES: Training Export (COMPLETED)>, <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (FAILED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (COMPLETED)>, <Task EXPORT_FEATURES: Training Export (COMPLETED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (COMPLETED)>, <Task EXPORT_FEATURES: Training Export (COMPLETED)>, <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (COMPLETED)>, <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (CANCELLED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (COMPLETED)>, <Task EXPORT_FEATURES: Training Export (COMPLETED)>, <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (CANCELLED)>, <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (FAILED)>, <Task INGEST_IMAGE: Ingest image: \"projects/earthengine-legacy/assets/users/rhtkhati/Classified_pixel_demo\" (FAILED)>, <Task INGEST_IMAGE: Ingest image: \"projects/earthengine-legacy/assets/users/rhtkhati/Classified_pixel_demo\" (FAILED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (COMPLETED)>, <Task EXPORT_FEATURES: Training Export (COMPLETED)>, <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (FAILED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (COMPLETED)>, <Task EXPORT_FEATURES: Training Export (COMPLETED)>, <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (FAILED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (COMPLETED)>, <Task EXPORT_FEATURES: Training Export (COMPLETED)>, <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (FAILED)>, <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (COMPLETED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (COMPLETED)>, <Task EXPORT_FEATURES: Training Export (COMPLETED)>, <Task INGEST_TABLE: Ingest table: \"projects/earthengine-legacy/assets/users/rhtkhati/ubon_lulcpoint\" (COMPLETED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (COMPLETED)>, <Task EXPORT_FEATURES: Training Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (COMPLETED)>, <Task EXPORT_FEATURES: Training Export (COMPLETED)>, <Task INGEST_TABLE: Ingest table: \"projects/earthengine-legacy/assets/users/rhtkhati/feat_to_point\" (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (FAILED)>, <Task EXPORT_FEATURES: Training Export (FAILED)>, <Task INGEST_TABLE: Ingest table: \"projects/earthengine-legacy/assets/users/rhtkhati/lulc_mask_lulc\" (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (FAILED)>, <Task EXPORT_FEATURES: Training Export (FAILED)>, <Task EXPORT_FEATURES: Testing Export (FAILED)>, <Task EXPORT_FEATURES: Training Export (FAILED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (FAILED)>, <Task EXPORT_FEATURES: Training Export (FAILED)>, <Task EXPORT_FEATURES: Testing Export (FAILED)>, <Task EXPORT_FEATURES: Training Export (FAILED)>, <Task EXPORT_FEATURES: Testing Export (FAILED)>, <Task EXPORT_FEATURES: Training Export (FAILED)>, <Task EXPORT_FEATURES: Testing Export (FAILED)>, <Task EXPORT_FEATURES: Training Export (FAILED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (FAILED)>, <Task EXPORT_FEATURES: Training Export (FAILED)>, <Task EXPORT_FEATURES: Testing Export (FAILED)>, <Task EXPORT_FEATURES: Training Export (FAILED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (FAILED)>, <Task EXPORT_FEATURES: Training Export (FAILED)>, <Task EXPORT_FEATURES: Testing Export (FAILED)>, <Task EXPORT_FEATURES: Training Export (FAILED)>, <Task INGEST_TABLE: Ingest table: \"projects/earthengine-legacy/assets/users/rhtkhati/ubon_lulc_84\" (COMPLETED)>, <Task EXPORT_IMAGE: Image Export (COMPLETED)>, <Task EXPORT_FEATURES: Testing Export (FAILED)>, <Task EXPORT_FEATURES: Training Export (FAILED)>, <Task INGEST_TABLE: Ingest table: \"projects/earthengine-legacy/assets/users/rhtkhati/lulc_ubon_data\" (COMPLETED)>]\n",
            "Polling for task (id: TEJPVRHH6ZULXOAAHSH7STTS).\n",
            "Done with training export.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFAYfCL-V3MH",
        "colab_type": "code",
        "outputId": "f6681fca-27c3-4799-fa8c-e992850d9edb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "fileNameSuffix = '.tfrecord.gz'\n",
        "trainFilePath = 'gs://' + outputBucket + '/' + trainFilePrefix + fileNameSuffix\n",
        "testFilePath = 'gs://' + outputBucket + '/' + testFilePrefix + fileNameSuffix\n",
        "\n",
        "print('Found training file.' if tf.gfile.Exists(trainFilePath) \n",
        "    else 'No training file found.')\n",
        "print('Found testing file.' if tf.gfile.Exists(testFilePath) \n",
        "    else 'No testing file found.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found training file.\n",
            "Found testing file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1pdDmJ5XN2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imageFilePrefix = 'Image_pixel_demo_'\n",
        "imageExportFormatOptions = {\n",
        "  'patchDimensions': [256, 256],\n",
        "  'maxFileSize': 104857600,\n",
        "  'compressed': True\n",
        "}\n",
        "exportRegion = ee.Geometry.Rectangle([104.78310511361235, 15.075894756514106, 105.19646570931548, 15.314444748491846])\n",
        "imageTask = ee.batch.Export.image.toCloudStorage(\n",
        "  image=image,\n",
        "  description='Image Export',\n",
        "  fileNamePrefix=imageFilePrefix,\n",
        "  bucket=outputBucket,\n",
        "  scale=10,\n",
        "  fileFormat='TFRecord',\n",
        "  region=exportRegion.toGeoJSON()['coordinates'],\n",
        "  formatOptions=imageExportFormatOptions,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stjazI4NaXon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imageTask.start()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TJX7zJUabFD",
        "colab_type": "code",
        "outputId": "5911ce14-6ac2-4c94-dc87-2f32823cfe59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "while imageTask.active():\n",
        "  print('Polling for task (id: {}).'.format(imageTask.id))\n",
        "  time.sleep(30)\n",
        "print('Done with image export.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Polling for task (id: KG7ZYA24GSLZXSQ5V2LQNNZK).\n",
            "Polling for task (id: KG7ZYA24GSLZXSQ5V2LQNNZK).\n",
            "Polling for task (id: KG7ZYA24GSLZXSQ5V2LQNNZK).\n",
            "Polling for task (id: KG7ZYA24GSLZXSQ5V2LQNNZK).\n",
            "Polling for task (id: KG7ZYA24GSLZXSQ5V2LQNNZK).\n",
            "Polling for task (id: KG7ZYA24GSLZXSQ5V2LQNNZK).\n",
            "Polling for task (id: KG7ZYA24GSLZXSQ5V2LQNNZK).\n",
            "Polling for task (id: KG7ZYA24GSLZXSQ5V2LQNNZK).\n",
            "Polling for task (id: KG7ZYA24GSLZXSQ5V2LQNNZK).\n",
            "Polling for task (id: KG7ZYA24GSLZXSQ5V2LQNNZK).\n",
            "Polling for task (id: KG7ZYA24GSLZXSQ5V2LQNNZK).\n",
            "Polling for task (id: KG7ZYA24GSLZXSQ5V2LQNNZK).\n",
            "Polling for task (id: KG7ZYA24GSLZXSQ5V2LQNNZK).\n",
            "Polling for task (id: KG7ZYA24GSLZXSQ5V2LQNNZK).\n",
            "Polling for task (id: KG7ZYA24GSLZXSQ5V2LQNNZK).\n",
            "Polling for task (id: KG7ZYA24GSLZXSQ5V2LQNNZK).\n",
            "Polling for task (id: KG7ZYA24GSLZXSQ5V2LQNNZK).\n",
            "Polling for task (id: KG7ZYA24GSLZXSQ5V2LQNNZK).\n",
            "Polling for task (id: KG7ZYA24GSLZXSQ5V2LQNNZK).\n",
            "Polling for task (id: KG7ZYA24GSLZXSQ5V2LQNNZK).\n",
            "Polling for task (id: KG7ZYA24GSLZXSQ5V2LQNNZK).\n",
            "Polling for task (id: KG7ZYA24GSLZXSQ5V2LQNNZK).\n",
            "Polling for task (id: KG7ZYA24GSLZXSQ5V2LQNNZK).\n",
            "Polling for task (id: KG7ZYA24GSLZXSQ5V2LQNNZK).\n",
            "Done with image export.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJB3v3mfafQb",
        "colab_type": "code",
        "outputId": "d3ba1cb3-5b5c-4e73-a1d0-15f1cca898c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "trainDataset = tf.data.TFRecordDataset(trainFilePath, compression_type='GZIP')\n",
        "print(iter(trainDataset).next())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'\\n\\x88\\x01\\n\\x0e\\n\\x02B2\\x12\\x08\\x12\\x06\\n\\x04H\\xbf\\xfd=\\n\\x0e\\n\\x02B3\\x12\\x08\\x12\\x06\\n\\x04!\\xb0\\xf2=\\n\\x0e\\n\\x02B4\\x12\\x08\\x12\\x06\\n\\x04\\xdfO\\r>\\n\\x0e\\n\\x02B8\\x12\\x08\\x12\\x06\\n\\x04\\xda\\x1b|>\\n\\x0f\\n\\x03B11\\x12\\x08\\x12\\x06\\n\\x04\\xf7\\xe4\\xc1>\\n\\x0f\\n\\x03B12\\x12\\x08\\x12\\x06\\n\\x04\\xd0\\xb3Y>\\n\\x10\\n\\x04QA60\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00\\n\\x12\\n\\x06lulcid\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x80?', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3I0ps75gRNM",
        "colab_type": "code",
        "outputId": "57eb0303-8f9b-4f0b-dc63-07ee184596b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "columns = [\n",
        "  tf.io.FixedLenFeature(shape=[1], dtype=tf.float32) for k in featureNames\n",
        "]\n",
        "featuresDict = dict(zip(featureNames, columns))\n",
        "\n",
        "pprint(featuresDict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'B11': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " 'B12': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " 'B2': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " 'B3': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " 'B4': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " 'B8': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " 'QA60': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " 'lulcid': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqN5hdHCv5KL",
        "colab_type": "code",
        "outputId": "7c47d272-e342-41c4-cb2a-b35a7aa098b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "def parse_tfrecord(example_proto):\n",
        "  parsed_features = tf.io.parse_single_example(example_proto, featuresDict)\n",
        "  labels = parsed_features.pop(label)\n",
        "  return parsed_features, tf.cast(labels, tf.int32)\n",
        "parsedDataset = trainDataset.map(parse_tfrecord, num_parallel_calls=5)\n",
        "pprint(iter(parsedDataset).next())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "({'B11': <tf.Tensor: id=54, shape=(1,), dtype=float32, numpy=array([0.3787], dtype=float32)>,\n",
            "  'B12': <tf.Tensor: id=55, shape=(1,), dtype=float32, numpy=array([0.2126], dtype=float32)>,\n",
            "  'B2': <tf.Tensor: id=56, shape=(1,), dtype=float32, numpy=array([0.1239], dtype=float32)>,\n",
            "  'B3': <tf.Tensor: id=57, shape=(1,), dtype=float32, numpy=array([0.1185], dtype=float32)>,\n",
            "  'B4': <tf.Tensor: id=58, shape=(1,), dtype=float32, numpy=array([0.138], dtype=float32)>,\n",
            "  'B8': <tf.Tensor: id=59, shape=(1,), dtype=float32, numpy=array([0.2462], dtype=float32)>,\n",
            "  'QA60': <tf.Tensor: id=60, shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>},\n",
            " <tf.Tensor: id=61, shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNimLVa06mqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalizedDifference(a, b):\n",
        "  nd = (a - b) / (a + b)\n",
        "  nd_inf = (a - b) / (a + b + 0.000001)\n",
        "  return tf.where(tf.math.is_finite(nd), nd, nd_inf)\n",
        "\n",
        "def addNDVI(features, label):\n",
        "  features['NDVI'] = normalizedDifference(features['B8'], features['B4'])\n",
        "  return features, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q73ZLNM6yhn",
        "colab_type": "code",
        "outputId": "a47e38c1-0428-483c-a062-aed1ae56b71a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from tensorflow import keras\n",
        "nClasses = 7\n",
        "inputDataset = parsedDataset.map(addNDVI)\n",
        "def toTuple(dict, label):\n",
        "  return tf.transpose(list(dict.values())), tf.one_hot(indices=label, depth=nClasses)\n",
        "inputDataset = inputDataset.map(toTuple).repeat().batch(10)\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(nClasses, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x=inputDataset, epochs=10, steps_per_epoch=100)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.4826 - acc: 0.6256\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.9340 - acc: 0.7991\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.8535 - acc: 0.7991\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.8384 - acc: 0.7991\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.8169 - acc: 0.7991\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.8104 - acc: 0.7991\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.7999 - acc: 0.7991\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.7973 - acc: 0.7991\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.7897 - acc: 0.7994\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.7793 - acc: 0.8027\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1c06afef98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJpx2DLS7oAG",
        "colab_type": "code",
        "outputId": "bb767e6c-9846-4c12-8607-fa74a2a98a54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "testDataset = (\n",
        "  tf.data.TFRecordDataset(testFilePath, compression_type='GZIP')\n",
        "    .map(parse_tfrecord, num_parallel_calls=5)\n",
        "    .map(addNDVI)\n",
        "    .map(toTuple)\n",
        "    .batch(1)\n",
        ")\n",
        "\n",
        "model.evaluate(testDataset, steps=45)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 1s 25ms/step - loss: 1.2170 - acc: 0.7111\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2170405407746634, 0.7111111]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhibYc4a8Yth",
        "colab_type": "code",
        "outputId": "719847e8-5a27-4f4c-b2c4-497d4be073b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "filesList = !gsutil ls 'gs://'{outputBucket}\n",
        "exportFilesList = [s for s in filesList if imageFilePrefix in s]\n",
        "imageFilesList = []\n",
        "jsonFile = None\n",
        "for f in exportFilesList:\n",
        "  if f.endswith('.tfrecord.gz'):\n",
        "    imageFilesList.append(f)\n",
        "  elif f.endswith('.json'):\n",
        "    jsonFile = f\n",
        "imageFilesList.sort()\n",
        "pprint(imageFilesList)\n",
        "print(jsonFile)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['gs://gic-rohit12.appspot.com/Image_pixel_demo_00000.tfrecord.gz',\n",
            " 'gs://gic-rohit12.appspot.com/Image_pixel_demo_00001.tfrecord.gz',\n",
            " 'gs://gic-rohit12.appspot.com/Image_pixel_demo_00002.tfrecord.gz',\n",
            " 'gs://gic-rohit12.appspot.com/Image_pixel_demo_00003.tfrecord.gz',\n",
            " 'gs://gic-rohit12.appspot.com/Image_pixel_demo_00004.tfrecord.gz',\n",
            " 'gs://gic-rohit12.appspot.com/Image_pixel_demo_00005.tfrecord.gz',\n",
            " 'gs://gic-rohit12.appspot.com/Image_pixel_demo_00006.tfrecord.gz',\n",
            " 'gs://gic-rohit12.appspot.com/Image_pixel_demo_00007.tfrecord.gz',\n",
            " 'gs://gic-rohit12.appspot.com/Image_pixel_demo_00008.tfrecord.gz',\n",
            " 'gs://gic-rohit12.appspot.com/Image_pixel_demo_00009.tfrecord.gz',\n",
            " 'gs://gic-rohit12.appspot.com/Image_pixel_demo_00010.tfrecord.gz']\n",
            "gs://gic-rohit12.appspot.com/Image_pixel_demo_mixer.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRK7EH8i8iMK",
        "colab_type": "code",
        "outputId": "5917c76f-1eee-4cbd-ffcb-cca64239cf73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "import json\n",
        "jsonText = !gsutil cat {jsonFile}\n",
        "mixer = json.loads(jsonText.nlstr)\n",
        "pprint(mixer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'patchDimensions': [256, 256],\n",
            " 'patchesPerRow': 17,\n",
            " 'projection': {'affine': {'doubleMatrix': [8.983152841195215e-05,\n",
            "                                            0.0,\n",
            "                                            104.78308800083747,\n",
            "                                            0.0,\n",
            "                                            -8.983152841195215e-05,\n",
            "                                            15.314568795198014]},\n",
            "                'crs': 'EPSG:4326'},\n",
            " 'totalPatches': 170}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1rx4KDU8j0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATCH_WIDTH = mixer['patchDimensions'][0]\n",
        "PATCH_HEIGHT = mixer['patchDimensions'][1]\n",
        "PATCHES = mixer['totalPatches']\n",
        "PATCH_DIMENSIONS_FLAT = [PATCH_WIDTH * PATCH_HEIGHT, 1]\n",
        "imageColumns = [\n",
        "  tf.FixedLenFeature(shape=PATCH_DIMENSIONS_FLAT, dtype=tf.float32) \n",
        "    for k in bands\n",
        "]\n",
        "\n",
        "imageFeaturesDict = dict(zip(bands, imageColumns))\n",
        "imageDataset = tf.data.TFRecordDataset(imageFilesList, compression_type='GZIP')\n",
        "def parse_image(example_proto):\n",
        "  return tf.io.parse_single_example(example_proto, imageFeaturesDict)\n",
        "imageDataset = imageDataset.map(parse_image, num_parallel_calls=7)\n",
        "imageDataset = imageDataset.flat_map(\n",
        "  lambda features: tf.data.Dataset.from_tensor_slices(features)\n",
        ")\n",
        "imageDataset = imageDataset.map(\n",
        "  lambda features: addNDVI(features, None)[0]\n",
        ")\n",
        "imageDataset = imageDataset.map(\n",
        "  lambda dataDict: (tf.transpose(list(dataDict.values())), tf.constant(-1))\n",
        ")\n",
        "imageDataset = imageDataset.batch(PATCH_WIDTH * PATCH_HEIGHT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNduj14M8tl5",
        "colab_type": "code",
        "outputId": "c74e7903-7f04-41ba-95b7-a3c624a932e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "predictions = model.predict(imageDataset, steps=PATCHES, verbose=1)\n",
        "print(predictions[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "170/170 [==============================] - 1217s 7s/step\n",
            "[[0.00125978 0.76983    0.0198909  0.05520608 0.00475137 0.11891824\n",
            "  0.03014366]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py5ke9PE83T-",
        "colab_type": "code",
        "outputId": "b21515e9-17b7-43a3-aac3-aa13f41774d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "outputImageFile = 'gs://' + outputBucket + '/Classified_pixel_demo.TFRecord'\n",
        "print('Writing to file ' + outputImageFile)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing to file gs://gic-rohit12.appspot.com/Classified_pixel_demo.TFRecord\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tnh_JP5F9Wl8",
        "colab_type": "code",
        "outputId": "e50cffb5-f726-4e73-8bd9-24217b32bd46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "writer = tf.python_io.TFRecordWriter(outputImageFile)\n",
        "patch = [[], [], [], [], [], [], [], []]\n",
        "curPatch = 1\n",
        "for prediction in predictions:\n",
        "  patch[0].append(tf.argmax(prediction, 1))\n",
        "  patch[1].append(prediction[0][0])\n",
        "  patch[2].append(prediction[0][1])\n",
        "  patch[3].append(prediction[0][2])\n",
        "  patch[4].append(prediction[0][3])\n",
        "  patch[5].append(prediction[0][4])\n",
        "  patch[6].append(prediction[0][5])\n",
        "  if (len(patch[0]) == PATCH_WIDTH * PATCH_HEIGHT):\n",
        "    print('Done with patch ' + str(curPatch) + ' of ' + str(PATCHES) + '...')\n",
        "    example = tf.train.Example(\n",
        "      features=tf.train.Features(\n",
        "        feature={\n",
        "          'prediction': tf.train.Feature(\n",
        "              int64_list=tf.train.Int64List(\n",
        "                  value=patch[0])),\n",
        "          'agricultureProb': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[1])),\n",
        "          'forestProb': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[2])),\n",
        "          'marshProb': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[3])),\n",
        "          'fieldsProb': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[4])),\n",
        "          'urbanprob': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[5])),\n",
        "          'waterProb': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[6])),\n",
        "        }\n",
        "      )\n",
        "    )\n",
        "    writer.write(example.SerializeToString())\n",
        "    patch = [[], [], [], [], [], [], []]\n",
        "    curPatch += 1\n",
        "\n",
        "writer.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done with patch 1 of 170...\n",
            "Done with patch 2 of 170...\n",
            "Done with patch 3 of 170...\n",
            "Done with patch 4 of 170...\n",
            "Done with patch 5 of 170...\n",
            "Done with patch 6 of 170...\n",
            "Done with patch 7 of 170...\n",
            "Done with patch 8 of 170...\n",
            "Done with patch 9 of 170...\n",
            "Done with patch 10 of 170...\n",
            "Done with patch 11 of 170...\n",
            "Done with patch 12 of 170...\n",
            "Done with patch 13 of 170...\n",
            "Done with patch 14 of 170...\n",
            "Done with patch 15 of 170...\n",
            "Done with patch 16 of 170...\n",
            "Done with patch 17 of 170...\n",
            "Done with patch 18 of 170...\n",
            "Done with patch 19 of 170...\n",
            "Done with patch 20 of 170...\n",
            "Done with patch 21 of 170...\n",
            "Done with patch 22 of 170...\n",
            "Done with patch 23 of 170...\n",
            "Done with patch 24 of 170...\n",
            "Done with patch 25 of 170...\n",
            "Done with patch 26 of 170...\n",
            "Done with patch 27 of 170...\n",
            "Done with patch 28 of 170...\n",
            "Done with patch 29 of 170...\n",
            "Done with patch 30 of 170...\n",
            "Done with patch 31 of 170...\n",
            "Done with patch 32 of 170...\n",
            "Done with patch 33 of 170...\n",
            "Done with patch 34 of 170...\n",
            "Done with patch 35 of 170...\n",
            "Done with patch 36 of 170...\n",
            "Done with patch 37 of 170...\n",
            "Done with patch 38 of 170...\n",
            "Done with patch 39 of 170...\n",
            "Done with patch 40 of 170...\n",
            "Done with patch 41 of 170...\n",
            "Done with patch 42 of 170...\n",
            "Done with patch 43 of 170...\n",
            "Done with patch 44 of 170...\n",
            "Done with patch 45 of 170...\n",
            "Done with patch 46 of 170...\n",
            "Done with patch 47 of 170...\n",
            "Done with patch 48 of 170...\n",
            "Done with patch 49 of 170...\n",
            "Done with patch 50 of 170...\n",
            "Done with patch 51 of 170...\n",
            "Done with patch 52 of 170...\n",
            "Done with patch 53 of 170...\n",
            "Done with patch 54 of 170...\n",
            "Done with patch 55 of 170...\n",
            "Done with patch 56 of 170...\n",
            "Done with patch 57 of 170...\n",
            "Done with patch 58 of 170...\n",
            "Done with patch 59 of 170...\n",
            "Done with patch 60 of 170...\n",
            "Done with patch 61 of 170...\n",
            "Done with patch 62 of 170...\n",
            "Done with patch 63 of 170...\n",
            "Done with patch 64 of 170...\n",
            "Done with patch 65 of 170...\n",
            "Done with patch 66 of 170...\n",
            "Done with patch 67 of 170...\n",
            "Done with patch 68 of 170...\n",
            "Done with patch 69 of 170...\n",
            "Done with patch 70 of 170...\n",
            "Done with patch 71 of 170...\n",
            "Done with patch 72 of 170...\n",
            "Done with patch 73 of 170...\n",
            "Done with patch 74 of 170...\n",
            "Done with patch 75 of 170...\n",
            "Done with patch 76 of 170...\n",
            "Done with patch 77 of 170...\n",
            "Done with patch 78 of 170...\n",
            "Done with patch 79 of 170...\n",
            "Done with patch 80 of 170...\n",
            "Done with patch 81 of 170...\n",
            "Done with patch 82 of 170...\n",
            "Done with patch 83 of 170...\n",
            "Done with patch 84 of 170...\n",
            "Done with patch 85 of 170...\n",
            "Done with patch 86 of 170...\n",
            "Done with patch 87 of 170...\n",
            "Done with patch 88 of 170...\n",
            "Done with patch 89 of 170...\n",
            "Done with patch 90 of 170...\n",
            "Done with patch 91 of 170...\n",
            "Done with patch 92 of 170...\n",
            "Done with patch 93 of 170...\n",
            "Done with patch 94 of 170...\n",
            "Done with patch 95 of 170...\n",
            "Done with patch 96 of 170...\n",
            "Done with patch 97 of 170...\n",
            "Done with patch 98 of 170...\n",
            "Done with patch 99 of 170...\n",
            "Done with patch 100 of 170...\n",
            "Done with patch 101 of 170...\n",
            "Done with patch 102 of 170...\n",
            "Done with patch 103 of 170...\n",
            "Done with patch 104 of 170...\n",
            "Done with patch 105 of 170...\n",
            "Done with patch 106 of 170...\n",
            "Done with patch 107 of 170...\n",
            "Done with patch 108 of 170...\n",
            "Done with patch 109 of 170...\n",
            "Done with patch 110 of 170...\n",
            "Done with patch 111 of 170...\n",
            "Done with patch 112 of 170...\n",
            "Done with patch 113 of 170...\n",
            "Done with patch 114 of 170...\n",
            "Done with patch 115 of 170...\n",
            "Done with patch 116 of 170...\n",
            "Done with patch 117 of 170...\n",
            "Done with patch 118 of 170...\n",
            "Done with patch 119 of 170...\n",
            "Done with patch 120 of 170...\n",
            "Done with patch 121 of 170...\n",
            "Done with patch 122 of 170...\n",
            "Done with patch 123 of 170...\n",
            "Done with patch 124 of 170...\n",
            "Done with patch 125 of 170...\n",
            "Done with patch 126 of 170...\n",
            "Done with patch 127 of 170...\n",
            "Done with patch 128 of 170...\n",
            "Done with patch 129 of 170...\n",
            "Done with patch 130 of 170...\n",
            "Done with patch 131 of 170...\n",
            "Done with patch 132 of 170...\n",
            "Done with patch 133 of 170...\n",
            "Done with patch 134 of 170...\n",
            "Done with patch 135 of 170...\n",
            "Done with patch 136 of 170...\n",
            "Done with patch 137 of 170...\n",
            "Done with patch 138 of 170...\n",
            "Done with patch 139 of 170...\n",
            "Done with patch 140 of 170...\n",
            "Done with patch 141 of 170...\n",
            "Done with patch 142 of 170...\n",
            "Done with patch 143 of 170...\n",
            "Done with patch 144 of 170...\n",
            "Done with patch 145 of 170...\n",
            "Done with patch 146 of 170...\n",
            "Done with patch 147 of 170...\n",
            "Done with patch 148 of 170...\n",
            "Done with patch 149 of 170...\n",
            "Done with patch 150 of 170...\n",
            "Done with patch 151 of 170...\n",
            "Done with patch 152 of 170...\n",
            "Done with patch 153 of 170...\n",
            "Done with patch 154 of 170...\n",
            "Done with patch 155 of 170...\n",
            "Done with patch 156 of 170...\n",
            "Done with patch 157 of 170...\n",
            "Done with patch 158 of 170...\n",
            "Done with patch 159 of 170...\n",
            "Done with patch 160 of 170...\n",
            "Done with patch 161 of 170...\n",
            "Done with patch 162 of 170...\n",
            "Done with patch 163 of 170...\n",
            "Done with patch 164 of 170...\n",
            "Done with patch 165 of 170...\n",
            "Done with patch 166 of 170...\n",
            "Done with patch 167 of 170...\n",
            "Done with patch 168 of 170...\n",
            "Done with patch 169 of 170...\n",
            "Done with patch 170 of 170...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPgMJPxM9XUg",
        "colab_type": "code",
        "outputId": "fd92bbb3-ec65-4971-ede6-8b6200eda315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!gsutil ls -l {outputImageFile}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 278565060  2020-01-14T09:20:55Z  gs://gic-rohit12.appspot.com/Classified_pixel_demo.TFRecord\n",
            "TOTAL: 1 objects, 278565060 bytes (265.66 MiB)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSlUgpY79aK1",
        "colab_type": "code",
        "outputId": "8b5259bc-b90f-4442-c836-ffe825d9fb0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "USER_NAME = 'rhtkhati'\n",
        "outputAssetID = 'users/' + USER_NAME + '/Classified_pixel_demo'\n",
        "print('Writing to ' + outputAssetID)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing to users/rhtkhati/Classified_pixel_demo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRycbtRD9rHN",
        "colab_type": "code",
        "outputId": "466521d8-f64e-4578-8c7d-8c6cd592cbd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!earthengine --no-use_cloud_api upload image --asset_id={outputAssetID} {outputImageFile} {jsonFile}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Started upload task with ID: J7J56OBWOASJC5AKCTYQVSTC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRgzcVK19rrP",
        "colab_type": "code",
        "outputId": "143b3d4b-c8b0-4d67-808c-04a9e4c0caac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "ee.batch.Task.list()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (RUNNING)>,\n",
              " <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (FAILED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task EXPORT_IMAGE: Deep_IMAGE (COMPLETED)>,\n",
              " <Task EXPORT_IMAGE: Deep_IMAGE (FAILED)>,\n",
              " <Task EXPORT_IMAGE: Deep_IMAGE (FAILED)>,\n",
              " <Task EXPORT_IMAGE: Deep_IMAGE (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (COMPLETED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (CANCELLED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (FAILED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (COMPLETED)>,\n",
              " <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (CANCELLED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (CANCELLED)>,\n",
              " <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (FAILED)>,\n",
              " <Task INGEST_IMAGE: Ingest image: \"projects/earthengine-legacy/assets/users/rhtkhati/Classified_pixel_demo\" (FAILED)>,\n",
              " <Task INGEST_IMAGE: Ingest image: \"projects/earthengine-legacy/assets/users/rhtkhati/Classified_pixel_demo\" (FAILED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (FAILED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (FAILED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (FAILED)>,\n",
              " <Task INGEST: Asset ingestion: users/rhtkhati/Classified_pixel_demo (COMPLETED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task INGEST_TABLE: Ingest table: \"projects/earthengine-legacy/assets/users/rhtkhati/ubon_lulcpoint\" (COMPLETED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task INGEST_TABLE: Ingest table: \"projects/earthengine-legacy/assets/users/rhtkhati/feat_to_point\" (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (FAILED)>,\n",
              " <Task INGEST_TABLE: Ingest table: \"projects/earthengine-legacy/assets/users/rhtkhati/lulc_mask_lulc\" (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (FAILED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (FAILED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (FAILED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (FAILED)>,\n",
              " <Task INGEST_TABLE: Ingest table: \"projects/earthengine-legacy/assets/users/rhtkhati/ubon_lulc_84\" (COMPLETED)>,\n",
              " <Task EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task EXPORT_FEATURES: Testing Export (FAILED)>,\n",
              " <Task EXPORT_FEATURES: Training Export (FAILED)>,\n",
              " <Task INGEST_TABLE: Ingest table: \"projects/earthengine-legacy/assets/users/rhtkhati/lulc_ubon_data\" (COMPLETED)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb3Hpd7M9t3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictionsImage = ee.Image(outputAssetID)\n",
        "\n",
        "predictionVis = {\n",
        "  'bands': 'prediction',\n",
        "  'min': 0,\n",
        "  'max': 2,\n",
        "  'palette': ['red', 'yellow', 'blue']\n",
        "}\n",
        "probabilityVis = {'bands': ['bareProb', 'vegProb', 'waterProb']}\n",
        "\n",
        "predictionMapid = predictionsImage.getMapId(predictionVis)\n",
        "probabilityMapid = predictionsImage.getMapId(probabilityVis)\n",
        "\n",
        "map = folium.Map(location=[15.2448, 104.8473])\n",
        "folium.TileLayer(\n",
        "  tiles=predictionMapid['tile_fetcher'].url_format,\n",
        "  attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "  overlay=True,\n",
        "  name='prediction',\n",
        ").add_to(map)\n",
        "folium.TileLayer(\n",
        "  tiles=probabilityMapid['tile_fetcher'].url_format,\n",
        "  attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "  overlay=True,\n",
        "  name='probability',\n",
        ").add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Islnb5lz9xM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = ee.Image(outputAssetID)\n",
        "predictionVis = {\n",
        "    'bands': 'prediction',\n",
        "  'min': 0,\n",
        "  'max': 4,\n",
        "  'palette': ['yellow', 'red','green', 'white','blue']\n",
        "}\n",
        "predictionMapid = predictionsImage.getMapId(predictionVis)\n",
        "map = folium.Map(location=[15.2448, 104.8473])\n",
        "folium.TileLayer(\n",
        "  tiles=predictionMapid['tile_fetcher'].url_format,\n",
        "  attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "  overlay=True,\n",
        "  name='prediction',\n",
        ").add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYPZxsKxvUaW",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}